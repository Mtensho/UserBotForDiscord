{"cells":[{"cell_type":"markdown","metadata":{"id":"HUQ4uA9v4O7e"},"source":["# LINEの会話履歴から学習用のデータセットづくり\n","5つまでの履歴をさかのぼる"]},{"cell_type":"markdown","source":["## ドライブにマウント"],"metadata":{"id":"NujUFgZpGx7q"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"l4m-BSQ8GvyD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd /content/drive/MyDrive/UserBot"],"metadata":{"id":"1NM8VcrjHKuV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TfCBpUlGGriK"},"source":["## 必要ライブラリのインストール"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJQIDxUoGriL"},"outputs":[],"source":["!pip install demoji"]},{"cell_type":"markdown","metadata":{"id":"65S-ArVBGriM"},"source":["## データセットの作成"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qBASfZuFGriM"},"outputs":[],"source":["import csv\n","import demoji\n","import re\n","\n","#自分のLINE名と会話相手のLINE名を入れる\n","User1=\"自分のLINE名\"\n","User2=\"会話相手のLINE名\"\n","\n","User_dict={User1:\"User1\",User2:\"User2\"}\n","\n","demoji.download_codes()\n","pattern1 = r\"https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+\"\n","pattern2 = r\"\\(.+?\\)\"\n","pattern = r\"[\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FFF0-9０-９a-zA-Z、。！？!?…]+\"\n","\n","log=[]\n","texts=[]\n","rows=[]\n","input_text=[]\n","m_log=\"\"\n","t_log=\"\"\n","pre_t_log=\"\"\n","pre_m_log=\"\"\n","with open('[LINE] ' + User2 + 'とのトーク.txt') as csvfile:\n","    reader = csv.reader(csvfile, delimiter='\\t', quotechar='\"')\n","    for row in reader:\n","        if len(row) > 0:\n","            if len(row) == 1:\n","                if \"202\" in row[0]:\n","                    log.append(row)\n","            elif row[2] != \"[スタンプ]\" and row[2] != \"[写真]\" and row[2] != \"[動画]\" :\n","                row[2]=demoji.replace(row[2])\n","                row[2]=row[2].replace(\"emoji\",\"\")\n","                temp = re.findall(pattern, row[2])\n","                text=[]\n","                for now in temp:\n","                    if len(now) >= 2:\n","                        if re.search(r\"[\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FFF]\", now):\n","                            text.append(now)\n","                row[2]=\"\".join(text)\n","                if len(row) == 1:\n","                    print(row)\n","                if len(row[2]) > 0:\n","                    log.append(row)\n","\n","log=log[2:]\n","result=[]\n","temp_log=[]\n","for now in log:\n","    if len(temp_log)>=5:\n","        temp_log=temp_log[1:]\n","    if len(now)==1:\n","        temp_log=[]\n","    elif now[1] == User2:\n","        text=\"<s>\"\n","        for i,t in enumerate(temp_log):\n","            text=text+\"<input\"+str(len(temp_log)-i)+\">\"+User_dict[t[1]]+\":\"+t[2]\n","        text=text+\"[SEP]\"+User_dict[now[1]]+\":\"+now[2]+\"</s>\"\n","        result.append([text])\n","        temp_log.append(now)\n","    else:\n","      temp_log.append(now)\n","\n","with open(\"train.txt\", \"w\") as fout:\n","    writer = csv.writer(fout)\n","    for now in result:\n","        writer.writerows([now])"]},{"cell_type":"markdown","metadata":{"id":"H5xFd3BOGriN"},"source":["# GPT-2のファインチューニング"]},{"cell_type":"markdown","metadata":{"id":"ZJsq76U7GriN"},"source":["## 必要ライブラリのインストール"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EmBcCGHTGriN"},"outputs":[],"source":["!pip install git+https://github.com/huggingface/transformers\n","# rinna/japanese-gpt2-mediumのtokenizerはsentencepieceなのでsentencepieceもインストールする必要があります。\n","!pip install sentencepiece\n","!pip install datasets\n","!pip install evaluate"]},{"cell_type":"markdown","metadata":{"id":"FE2IyX0MGriO"},"source":["## 追加学習の実行"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2noCWsJGriO"},"outputs":[],"source":["! python ./run_clm.py --model_name_or_path=rinna/japanese-gpt2-medium --train_file=train.txt --validation_file=train.txt --do_train --do_eval --num_train_epochs=8 --save_steps=10000 --save_total_limit=3 --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --output_dir=./output --use_fast_tokenizer=False"]},{"cell_type":"markdown","metadata":{"id":"rbASshdjGriO"},"source":["## 作成したモデルで対話文を生成"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ypUX3cmqGriP"},"outputs":[],"source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"rinna/japanese-gpt2-medium\")\n","tokenizer.do_lower_case = True\n","model = AutoModelForCausalLM.from_pretrained('output/')\n","model.to(device)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V5mkrAmqGriP"},"outputs":[],"source":["def generate_return(input, num_gen=1):\n","    input_text = '<s>'+ input + '[SEP]'\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n","    out = model.generate(input_ids, do_sample=True, top_p=0.95, top_k=40, \n","                         num_return_sequences=num_gen, max_length=256, bad_words_ids=[[1], [5]])\n","    print('-'*5, '生成された返答', '-'*5)\n","    for sent in tokenizer.batch_decode(out):\n","        sent = sent.split('[SEP]</s>')[1]\n","        sent = sent.replace('</s>', '')\n","        print(sent)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tmZ2HrcgGriP"},"outputs":[],"source":["generate_return('おはよう')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}